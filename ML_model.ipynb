{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b27ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install earthaccess xarray h5netcdf -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fff9150",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d174684",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install earthaccess xarray h5netcdf dask scikit-learn joblib pandas -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "039b274b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dante.torres_pragma\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Authentication successful.\n"
     ]
    }
   ],
   "source": [
    "import earthaccess\n",
    "import xarray as xr\n",
    "\n",
    "try:\n",
    "    earthaccess.login()\n",
    "    print(\"✅ Authentication successful.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Authentication error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a663362",
   "metadata": {},
   "source": [
    "You can access the training data through your dataEarth credentials.\n",
    "\n",
    "User: patriciotorres\n",
    "pass: *********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d28976b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data collection for the Arequipa region from 2024-01-01 to 2024-01-30...\n",
      "   Processing month: 2024-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 31/31 [00:00<00:00, 373.74it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 31/31 [12:01<00:00, 23.29s/it]  \n",
      "COLLECTING RESULTS | : 100%|██████████| 31/31 [00:00<00:00, 1637.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Regional data from 2024-01 extracted.\n",
      "\n",
      "Consolidating all regional data...\n",
      "Consolidated dataset. Preparing features...\n",
      "Calculating historical averages for the prediction function...\n",
      "\n",
      "Starting training with 31248 records...\n",
      "Training Temperature model...\n",
      "Regional Temperature model saved.\n",
      "\n",
      "Training Rain Probability model...\n",
      "Regional Rain model saved.\n",
      "\n",
      "Training model for Wind U-Component...\n",
      "Regional Wind U model saved.\n",
      "\n",
      "Training model for Wind V-Component...\n",
      "Regional Wind V model saved.\n",
      "\n",
      "Training Humidity model...\n",
      "Regional Humidity model saved.\n",
      "\n",
      "--- Training completed and corrected! ---\n"
     ]
    }
   ],
   "source": [
    "import earthaccess\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- 1. Geographic and Temporal Configuration ---\n",
    "AREQUIPA_BOUNDS = {\n",
    "    'lat_min': -17.5,\n",
    "    'lat_max': -14.5,\n",
    "    'lon_min': -75.5,\n",
    "    'lon_max': -71.0\n",
    "}\n",
    "# Date range for data extraction\n",
    "HISTORICAL_START = \"2024-01-01\"\n",
    "HISTORICAL_END = \"2024-01-30\"\n",
    "\n",
    "# --- REGIONAL DATA EXTRACTION ---\n",
    "processing_months = pd.date_range(start=HISTORICAL_START, end=HISTORICAL_END, freq='MS')\n",
    "all_regional_data = []\n",
    "\n",
    "print(f\"Starting data collection for the Arequipa region from {HISTORICAL_START} to {HISTORICAL_END}...\")\n",
    "\n",
    "for month_start in processing_months:\n",
    "    month_end = month_start + pd.offsets.MonthEnd(1)\n",
    "    month_str = month_start.strftime('%Y-%m')\n",
    "    temp_path_month = f\"./temp_data_{month_str}/\"\n",
    "\n",
    "    print(f\"   Processing month: {month_str}\")\n",
    "\n",
    "    try:\n",
    "        os.makedirs(temp_path_month, exist_ok=True)\n",
    "        results = earthaccess.search_data(\n",
    "            doi='10.5067/7MCPBJ41Y0K6',\n",
    "            temporal=(month_start.strftime('%Y-%m-%d'), month_end.strftime('%Y-%m-%d')),\n",
    "            bounding_box=(AREQUIPA_BOUNDS['lon_min'], AREQUIPA_BOUNDS['lat_min'], AREQUIPA_BOUNDS['lon_max'], AREQUIPA_BOUNDS['lat_max'])\n",
    "        )\n",
    "\n",
    "        if not results:\n",
    "            print(f\"     No data found for {month_str}.\")\n",
    "            continue\n",
    "\n",
    "        earthaccess.download(results, local_path=temp_path_month)\n",
    "\n",
    "        local_files = glob.glob(os.path.join(temp_path_month, \"*.nc4\"))\n",
    "        if not local_files:\n",
    "            continue\n",
    "\n",
    "        with xr.open_mfdataset(local_files, engine=\"h5netcdf\", combine='by_coords') as ds_month:\n",
    "            regional_data = ds_month.sel(\n",
    "                lat=slice(AREQUIPA_BOUNDS['lat_min'], AREQUIPA_BOUNDS['lat_max']),\n",
    "                lon=slice(AREQUIPA_BOUNDS['lon_min'], AREQUIPA_BOUNDS['lon_max'])\n",
    "            )\n",
    "            df_regional = regional_data.load().to_dataframe()\n",
    "            all_regional_data.append(df_regional)\n",
    "            print(f\"     Regional data from {month_str} extracted.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"     An error occurred in {month_str}: {e}\")\n",
    "    finally:\n",
    "        if os.path.exists(temp_path_month):\n",
    "            shutil.rmtree(temp_path_month)\n",
    "\n",
    "# --- CONSOLIDATION AND FINAL PREPARATION ---\n",
    "print(\"\\nConsolidating all regional data...\")\n",
    "if not all_regional_data:\n",
    "    print(\"No data was collected. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "historical_df = pd.concat(all_regional_data)\n",
    "print(\"Consolidated dataset. Preparing features...\")\n",
    "\n",
    "historical_df = historical_df.reset_index()\n",
    "\n",
    "historical_df.rename(columns={'time': 'timestamp'}, inplace=True)\n",
    "historical_df['hour'] = historical_df['timestamp'].dt.hour\n",
    "historical_df['dayofyear'] = historical_df['timestamp'].dt.dayofyear\n",
    "historical_df['month'] = historical_df['timestamp'].dt.month\n",
    "historical_df['will_rain'] = (historical_df['PRECTOTCORR'] > 0.1).astype(int)\n",
    "historical_df.dropna(inplace=True)\n",
    "\n",
    "print(\"Calculating historical averages for the prediction function...\")\n",
    "historical_means = historical_df.groupby(['dayofyear', 'hour', 'lat', 'lon']).mean(numeric_only=True)\n",
    "historical_means.to_pickle(\"historical_means_regional.pkl\")\n",
    "\n",
    "# --- REGIONAL MODEL TRAINING ---\n",
    "\n",
    "features = [\n",
    "  \"TLML\",         # Temperature\n",
    "  \"PRECTOTCORR\",  # Rainfall Amount\n",
    "  \"QLML\",         # Humidity\n",
    "  \"ULML\",         # Wind U-Component\n",
    "  \"VLML\"          # Wind V-Component\n",
    "]\n",
    "X_base = historical_df[features]\n",
    "\n",
    "y_temp = historical_df['TLML']\n",
    "y_will_rain_class = historical_df['will_rain']\n",
    "y_wind_u = historical_df['ULML']\n",
    "y_wind_v = historical_df['VLML']\n",
    "y_humidity = historical_df['QLML']\n",
    "\n",
    "print(f\"\\nStarting training with {len(X_base)} records...\")\n",
    "\n",
    "# --- Temperature (Regression) ---\n",
    "print(\"Training Temperature model...\")\n",
    "\n",
    "X_for_temp = X_base.drop('TLML', axis=1)\n",
    "model_temp = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, min_samples_leaf=5)\n",
    "model_temp.fit(X_for_temp, y_temp)\n",
    "joblib.dump(model_temp, 'regional_model_temperature.joblib')\n",
    "print(\"Regional Temperature model saved.\")\n",
    "\n",
    "# --- Rain Probability (Classification) ---\n",
    "print(\"\\nTraining Rain Probability model...\")\n",
    "X_for_rain = X_base.drop('PRECTOTCORR', axis=1)\n",
    "model_rain = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, min_samples_leaf=5)\n",
    "model_rain.fit(X_for_rain, y_will_rain_class)\n",
    "joblib.dump(model_rain, 'regional_model_rain.joblib')\n",
    "print(\"Regional Rain model saved.\")\n",
    "\n",
    "# --- Wind U (Regression) ---\n",
    "print(\"\\nTraining model for Wind U-Component...\")\n",
    "X_for_wind_u = X_base.drop('ULML', axis=1)\n",
    "model_wind_u = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, min_samples_leaf=5)\n",
    "model_wind_u.fit(X_for_wind_u, y_wind_u)\n",
    "joblib.dump(model_wind_u, 'regional_model_wind_u.joblib')\n",
    "print(\"Regional Wind U model saved.\")\n",
    "\n",
    "# --- Wind V (Regression) ---\n",
    "print(\"\\nTraining model for Wind V-Component...\")\n",
    "X_for_wind_v = X_base.drop('VLML', axis=1)\n",
    "model_wind_v = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, min_samples_leaf=5)\n",
    "model_wind_v.fit(X_for_wind_v, y_wind_v)\n",
    "joblib.dump(model_wind_v, 'regional_model_wind_v.joblib')\n",
    "print(\"Regional Wind V model saved.\")\n",
    "\n",
    "# --- Humidity (Regression) ---\n",
    "print(\"\\nTraining Humidity model...\")\n",
    "X_for_humidity = X_base.drop('QLML', axis=1)\n",
    "model_humidity = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, min_samples_leaf=5)\n",
    "model_humidity.fit(X_for_humidity, y_humidity)\n",
    "joblib.dump(model_humidity, 'regional_model_humidity.joblib')\n",
    "print(\"Regional Humidity model saved.\")\n",
    "\n",
    "print(\"\\n--- Training completed and corrected! ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
